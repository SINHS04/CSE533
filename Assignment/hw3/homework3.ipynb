{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions from _01_code/_99_common_utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_linux():\n",
    "    if sys.platform.startswith(\"linux\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_windows():\n",
    "    if os.name == \"nt\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_mac():\n",
    "    if sys.platform == \"darwin\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_num_cpu_cores():\n",
    "    import multiprocessing\n",
    "    return multiprocessing.cpu_count()\n",
    "\n",
    "class DeltaTemplate(Template):\n",
    "    delimiter = \"%\"\n",
    "\n",
    "    def strfdelta(tdelta, fmt):\n",
    "        d = {\"D\": tdelta.days}\n",
    "        d[\"H\"], rem = divmod(tdelta.seconds, 3600)\n",
    "        d[\"M\"], d[\"S\"] = divmod(rem, 60)\n",
    "        t = DeltaTemplate(fmt)\n",
    "        return t.substitute(**d)\n",
    "\n",
    "def strfdelta(td, fmt):\n",
    "\n",
    "    # Get the timedelta’s sign and absolute number of seconds.\n",
    "    sign = \"-\" if td.days < 0 else \"+\"\n",
    "    secs = abs(td).total_seconds()\n",
    "\n",
    "    # Break the seconds into more readable quantities.\n",
    "    days, rem = divmod(secs, 86400)  # Seconds per day: 24 * 60 * 60\n",
    "    hours, rem = divmod(rem, 3600)  # Seconds per hour: 60 * 60\n",
    "    mins, secs = divmod(rem, 60)\n",
    "\n",
    "    # Format (as per above answers) and return the result string.\n",
    "    t = DeltaTemplate(fmt)\n",
    "    return t.substitute(\n",
    "        s=sign,\n",
    "        D=\"{:d}\".format(int(days)),\n",
    "        H=\"{:02d}\".format(int(hours)),\n",
    "        M=\"{:02d}\".format(int(mins)),\n",
    "        S=\"{:02d}\".format(int(secs)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [문제 1] Fashion MNIST 데이터 정규화를 위한 Mean과 Std값 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment function\n",
    "def augment_f_mnist_train(f_mnist_train):\n",
    "    f_mnist_train_transforms = nn.Sequential(\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.CenterCrop([28, 28]),\n",
    "        transforms.RandomCrop([28, 28]),\n",
    "    )\n",
    "\n",
    "    transformed_train_data = []\n",
    "\n",
    "    for image, label in f_mnist_train:\n",
    "        transformed_image = f_mnist_train_transforms(image)\n",
    "        transformed_train_data.append((transformed_image, label))\n",
    "\n",
    "    f_mnist_train = ConcatDataset([f_mnist_train, transformed_train_data])\n",
    "\n",
    "    return f_mnist_train\n",
    "\n",
    "def get_f_mnist_train_data():\n",
    "    data_path = \".\" \n",
    "\n",
    "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "\n",
    "    imgs = [img for img, _ in f_mnist_train]\n",
    "    imgs = torch.concat(imgs, dim=0)\n",
    "    mean = imgs.mean(dim=[0, 1, 2])\n",
    "    std = imgs.std(dim=[0, 1, 2])\n",
    "\n",
    "    ## augment ##\n",
    "    f_mnist_train = augment_f_mnist_train(f_mnist_train)\n",
    "    print(len(f_mnist_train))\n",
    "    ##############\n",
    "\n",
    "    num_data_loading_workers = get_num_cpu_cores() if is_linux() or is_windows() else 0\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    )\n",
    "    \n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms, mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_mnist_test_data(mean, std):\n",
    "    data_path = \".\"\n",
    "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet(CNN) Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_googlenet_model():\n",
    "    class Inception(nn.Module):\n",
    "        def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "            super(Inception, self).__init__(**kwargs)\n",
    "            self.b1_1 = nn.LazyConv2d(out_channels=c1, kernel_size=1)\n",
    "\n",
    "            self.b2_1 = nn.LazyConv2d(out_channels=c2[0], kernel_size=1)\n",
    "            self.b2_2 = nn.LazyConv2d(out_channels=c2[1], kernel_size=3, padding=1)\n",
    "\n",
    "            self.b3_1 = nn.LazyConv2d(out_channels=c3[0], kernel_size=1)\n",
    "            self.b3_2 = nn.LazyConv2d(out_channels=c3[1], kernel_size=5, padding=2)\n",
    "\n",
    "            self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "            self.b4_2 = nn.LazyConv2d(out_channels=c4, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            b1 = torch.relu(self.b1_1(x))\n",
    "            b2 = torch.relu(self.b2_2(torch.relu(self.b2_1(x))))\n",
    "            b3 = torch.relu(self.b3_2(torch.relu(self.b3_1(x))))\n",
    "            b4 = torch.relu(self.b4_2(self.b4_1(x)))\n",
    "            return torch.cat((b1, b2, b3, b4), dim=1)\n",
    "        \n",
    "    class InceptionAux(nn.Module):\n",
    "        def __init__(self, n_outputs, **kwargs):\n",
    "            super(InceptionAux, self).__init__(**kwargs)\n",
    "\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.LazyConv2d(out_channels=128, kernel_size=1),\n",
    "            )\n",
    "\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.LazyLinear(out_features=1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                nn.LazyLinear(out_features=n_outputs),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "        \n",
    "    class GoogleNet(nn.Module):\n",
    "        def __init__(self, n_outputs=10):\n",
    "            super(GoogleNet, self).__init__()\n",
    "            self.conv_block = nn.Sequential(self.conv_blk_1(), self.conv_blk_2())\n",
    "            self.inception_block_1 = self.inception_blk_1()\n",
    "            self.inception_block_2 = self.inception_blk_2()\n",
    "            self.inception_block_3 = self.inception_blk_3()\n",
    "            self.aux_1 = InceptionAux(n_outputs)\n",
    "            self.aux_2 = InceptionAux(n_outputs)\n",
    "\n",
    "        def conv_blk_1(self):\n",
    "            return nn.Sequential(\n",
    "                nn.LazyConv2d(out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            )\n",
    "        \n",
    "        def conv_blk_2(self):\n",
    "            return nn.Sequential(\n",
    "                nn.LazyConv2d(out_channels=64, kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.LazyConv2d(out_channels=192, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            )\n",
    "        \n",
    "        def inception_blk_1(self):\n",
    "            return nn.Sequential(\n",
    "                Inception(c1=64, c2=(96, 128), c3=(16, 32), c4=32),\n",
    "                Inception(c1=128, c2=(128, 192), c3=(32, 96), c4=64),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                Inception(c1=192, c2=(96, 208), c3=(16, 48), c4=64),\n",
    "            )\n",
    "        \n",
    "        def inception_blk_2(self):\n",
    "            return nn.Sequential(\n",
    "                Inception(c1=160, c2=(112, 224), c3=(24, 64), c4=64),\n",
    "                Inception(c1=128, c2=(128, 256), c3=(24, 64), c4=64),\n",
    "                Inception(c1=112, c2=(144, 288), c3=(32, 64), c4=64),\n",
    "            )\n",
    "        \n",
    "        def inception_blk_3(self):\n",
    "            return nn.Sequential(\n",
    "                Inception(c1=256, c2=(160, 320), c3=(32, 128), c4=128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                Inception(c1=256, c2=(160, 320), c3=(32, 128), c4=128),\n",
    "                Inception(c1=384, c2=(192, 384), c3=(48, 128), c4=128),\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv_block(x)\n",
    "            x = self.inception_block_1(x)\n",
    "            aux_out_1 = self.aux_1(x)\n",
    "            x = self.inception_block_2(x)\n",
    "            aux_out_2 = self.aux_2(x)\n",
    "            x = self.inception_block_3(x)\n",
    "            return x, aux_out_1, aux_out_2\n",
    "\n",
    "    my_model = GoogleNet()\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "  \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "  def __init__(self, patience=10, delta=0.00001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
    "    self.patience = patience\n",
    "    self.counter = 0\n",
    "    self.delta = delta\n",
    "\n",
    "    self.val_loss_min = None\n",
    "    self.file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
    "    )\n",
    "    self.latest_file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "    )\n",
    "\n",
    "  def check_and_save(self, new_validation_loss, model):\n",
    "    early_stop = False\n",
    "\n",
    "    if self.val_loss_min is None:\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      message = f'Early stopping is stated!'\n",
    "    elif new_validation_loss < self.val_loss_min - self.delta:\n",
    "      message = f'V_loss decreased ({self.val_loss_min:7.5f} --> {new_validation_loss:7.5f}). Saving model...'\n",
    "      self.save_checkpoint(new_validation_loss, model)\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      self.counter = 0\n",
    "    else:\n",
    "      self.counter += 1\n",
    "      message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
    "      if self.counter >= self.patience:\n",
    "        early_stop = True\n",
    "        message += \" *** TRAIN EARLY STOPPED! ***\"\n",
    "\n",
    "    return message, early_stop\n",
    "\n",
    "  def save_checkpoint(self, val_loss, model):\n",
    "    '''Saves model when validation loss decrease.'''\n",
    "    torch.save(model.state_dict(), self.file_path)\n",
    "    torch.save(model.state_dict(), self.latest_file_path)\n",
    "    self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClassificationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTrainer:\n",
    "  def __init__(\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "  ):\n",
    "    self.project_name = project_name\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.train_data_loader = train_data_loader\n",
    "    self.validation_data_loader = validation_data_loader\n",
    "    self.transforms = transforms\n",
    "    self.run_time_str = run_time_str\n",
    "    self.wandb = wandb\n",
    "    self.device = device\n",
    "    self.checkpoint_file_path = checkpoint_file_path\n",
    "\n",
    "    # Use a built-in loss function\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  def do_train(self):\n",
    "    self.model.train()  # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_train = 0.0\n",
    "    num_corrects_train = 0\n",
    "    num_trained_samples = 0\n",
    "    num_trains = 0\n",
    "\n",
    "    for train_batch in self.train_data_loader:\n",
    "      input_train, target_train = train_batch\n",
    "      input_train = input_train.to(device=self.device)\n",
    "      target_train = target_train.to(device=self.device)\n",
    "\n",
    "      if self.transforms:\n",
    "        input_train = self.transforms(input_train)\n",
    "\n",
    "      output_train = self.model(input_train)\n",
    "\n",
    "      loss = self.loss_fn(output_train, target_train)\n",
    "      loss_train += loss.item()\n",
    "\n",
    "      predicted_train = torch.argmax(output_train, dim=1)\n",
    "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "      num_trained_samples += len(input_train)\n",
    "      num_trains += 1\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "    train_loss = loss_train / num_trains\n",
    "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "  def do_validation(self):\n",
    "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_corrects_validation = 0\n",
    "    num_validated_samples = 0\n",
    "    num_validations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in self.validation_data_loader:\n",
    "        input_validation, target_validation = validation_batch\n",
    "        input_validation = input_validation.to(device=self.device)\n",
    "        target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "        if self.transforms:\n",
    "          input_validation = self.transforms(input_validation)\n",
    "\n",
    "        output_validation = self.model(input_validation)\n",
    "        loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
    "\n",
    "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "        num_validated_samples += len(input_validation)\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "    return validation_loss, validation_accuracy\n",
    "\n",
    "  def train_loop(self):\n",
    "    early_stopping = EarlyStopping(\n",
    "      patience=self.wandb.config.early_stop_patience,\n",
    "      delta=self.wandb.config.early_stop_delta,\n",
    "      project_name=self.project_name,\n",
    "      checkpoint_file_path=self.checkpoint_file_path,\n",
    "      run_time_str=self.run_time_str\n",
    "    )\n",
    "    n_epochs = self.wandb.config.epochs\n",
    "    training_start_time = datetime.now()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      train_loss, train_accuracy = self.do_train()\n",
    "\n",
    "      if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "        validation_loss, validation_accuracy = self.do_validation()\n",
    "\n",
    "        elapsed_time = datetime.now() - training_start_time\n",
    "        epoch_per_second = 0 if elapsed_time.seconds == 0 else epoch / elapsed_time.seconds\n",
    "\n",
    "        message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "\n",
    "        print(\n",
    "          f\"[Epoch {epoch:>3}] \"\n",
    "          f\"T_loss: {train_loss:7.5f}, \"\n",
    "          f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "          f\"V_loss: {validation_loss:7.5f}, \"\n",
    "          f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "          f\"{message} | \"\n",
    "          f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "          f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "        )\n",
    "\n",
    "        self.wandb.log({\n",
    "          \"Epoch\": epoch,\n",
    "          \"Training loss\": train_loss,\n",
    "          \"Training accuracy (%)\": train_accuracy,\n",
    "          \"Validation loss\": validation_loss,\n",
    "          \"Validation accuracy (%)\": validation_accuracy,\n",
    "          \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "        })\n",
    "\n",
    "        if early_stop:\n",
    "          break\n",
    "\n",
    "    elapsed_time = datetime.now() - training_start_time\n",
    "    print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClassificationTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTester:\n",
    "  def __init__(self, project_name, model, test_data_loader, transforms, checkpoint_file_path):\n",
    "    self.project_name = project_name\n",
    "    self.model = model\n",
    "    self.test_data_loader = test_data_loader\n",
    "    self.transforms = transforms\n",
    "\n",
    "    self.latest_file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "    )\n",
    "\n",
    "    print(\"MODEL FILE: {0}\".format(self.latest_file_path))\n",
    "\n",
    "    self.model.load_state_dict(torch.load(self.latest_file_path, map_location=torch.device('cpu')))\n",
    "\n",
    "  def test(self):\n",
    "    self.model.eval()    # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    num_corrects_test = 0\n",
    "    num_tested_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for test_batch in self.test_data_loader:\n",
    "        input_test, target_test = test_batch\n",
    "\n",
    "        input_test = self.transforms(input_test)\n",
    "\n",
    "        output_test, _, _ = self.model(input_test)\n",
    "\n",
    "        predicted_test = torch.argmax(output_test, dim=1)\n",
    "        num_corrects_test += torch.sum(torch.eq(predicted_test, target_test))\n",
    "\n",
    "        num_tested_samples += len(input_test)\n",
    "\n",
    "      test_accuracy = 100.0 * num_corrects_test / num_tested_samples\n",
    "\n",
    "    print(f\"TEST RESULTS: {test_accuracy:6.3f}%\")\n",
    "\n",
    "  def test_single(self, input_test):\n",
    "    self.model.eval()    # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    with torch.no_grad():\n",
    "      input_test = self.transforms(input_test)\n",
    "\n",
    "      output_test, _, _ = self.model(input_test)\n",
    "      predicted_test = torch.argmax(output_test, dim=1)\n",
    "\n",
    "    return predicted_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNetClassificationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNetClassificationTrainer(ClassificationTrainer):\n",
    "  def __init__(\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "  ):\n",
    "    super(GoogLeNetClassificationTrainer, self).__init__(\n",
    "      project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "      run_time_str, wandb, device, checkpoint_file_path\n",
    "    )\n",
    "\n",
    "  def do_train(self):\n",
    "    self.model.train()  # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_train = 0.0\n",
    "    num_corrects_train = 0\n",
    "    num_trained_samples = 0\n",
    "    num_trains = 0\n",
    "\n",
    "    for train_batch in self.train_data_loader:\n",
    "      input_train, target_train = train_batch\n",
    "      input_train = input_train.to(device=self.device)\n",
    "      target_train = target_train.to(device=self.device)\n",
    "\n",
    "      input_train = self.transforms(input_train)\n",
    "\n",
    "      output_train, output_train_ax_1, output_train_ax_2 = self.model(input_train)\n",
    "      loss = self.loss_fn(output_train, target_train)\n",
    "      loss_aux_1 = self.loss_fn(output_train_ax_1, target_train)\n",
    "      loss_aux_2 = self.loss_fn(output_train_ax_2, target_train)\n",
    "      loss += 0.3 * (loss_aux_1 + loss_aux_2)\n",
    "\n",
    "      loss_train += loss.item()\n",
    "\n",
    "      predicted_train = torch.argmax(output_train, dim=1)\n",
    "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "      num_trained_samples += len(input_train)\n",
    "      num_trains += 1\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "    train_loss = loss_train / num_trains\n",
    "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "  def do_validation(self):\n",
    "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_corrects_validation = 0\n",
    "    num_validated_samples = 0\n",
    "    num_validations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in self.validation_data_loader:\n",
    "        input_validation, target_validation = validation_batch\n",
    "        input_validation = input_validation.to(device=self.device)\n",
    "        target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "        input_validation = self.transforms(input_validation)\n",
    "\n",
    "        output_validation, output_validation_ax_1, output_validation_ax_2 = self.model(input_validation)\n",
    "        loss_validation = self.loss_fn(output_validation, target_validation)\n",
    "        loss_validation_aux_1 = self.loss_fn(output_validation_ax_1, target_validation)\n",
    "        loss_validation_aux_2 = self.loss_fn(output_validation_ax_2, target_validation)\n",
    "        loss_validation += 0.3 * (loss_validation_aux_1 + loss_validation_aux_2)\n",
    "        loss_validation += loss_validation.item()\n",
    "\n",
    "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "        num_validated_samples += len(input_validation)\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(config):\n",
    "    train_data_loader, validation_data_loader, f_mnist_transforms, mean, std = get_f_mnist_train_data()\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = get_googlenet_model()\n",
    "    # best_path = 'checkpoints/CSE533_Fashion_MNIST_checkpoint_2023-11-18_00-17-29.pt'\n",
    "    # best_path = 'checkpoints/CSE533_Fashion_MNIST_checkpoint_2023-11-18_05-14-41.pt'\n",
    "    # model.load_state_dict(torch.load(best_path, map_location=torch.device('cpu')))\n",
    "    model.to(device)\n",
    "\n",
    "    summary(\n",
    "        model = model,\n",
    "        input_size=(1, 1, 28, 28),\n",
    "        col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\", \"mult_adds\"]\n",
    "    )\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=wandb.config.learning_rate,\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "\n",
    "    classification_trainer = GoogLeNetClassificationTrainer(\n",
    "        config['project'], model, optimizer, train_data_loader, validation_data_loader, f_mnist_transforms,\n",
    "        config['current_time_str'], wandb, device, config['checkpoints_path']\n",
    "    )\n",
    "\n",
    "    classification_trainer.train_loop()\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(config, mean, std):\n",
    "    f_mnist_test_images, test_data_loader, f_mnist_transforms = get_f_mnist_test_data(mean, std)\n",
    "\n",
    "    test_model = get_googlenet_model()\n",
    "\n",
    "    classification_tester = ClassificationTester(\n",
    "        config['project'], test_model, test_data_loader, f_mnist_transforms, config['checkpoints_path']\n",
    "    )\n",
    "    classification_tester.test()\n",
    "\n",
    "    # img, label = f_mnist_test_images[0]\n",
    "    # print(\"     LABEL:\", label)\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "    \n",
    "    # output = classification_tester.test_single(\n",
    "    #     torch.tensor(np.array(f_mnist_test_images[0][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "    # )\n",
    "    # print(\"PREDICTION:\", output)\n",
    "\n",
    "    while True:\n",
    "        correct = 0\n",
    "        wrong = 0\n",
    "        correct_imgs = []\n",
    "        wrong_imgs = []\n",
    "\n",
    "        number = list([i for i in range(10_000)])\n",
    "        select = random.sample(number, 10)\n",
    "        for idx in select:\n",
    "            output = classification_tester.test_single(\n",
    "                torch.tensor(np.array(f_mnist_test_images[idx][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "            )\n",
    "            label = f_mnist_test_images[idx][1]\n",
    "            if label == output:\n",
    "                correct += 1\n",
    "                correct_imgs.append(f_mnist_test_images[idx])\n",
    "            else:\n",
    "                wrong += 1\n",
    "                wrong_imgs.append(f_mnist_test_images[idx])\n",
    "\n",
    "        if wrong > 0:\n",
    "            for img in wrong_imgs:\n",
    "                output = classification_tester.test_single(\n",
    "                    torch.tensor(np.array(f_mnist_test_images[idx][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "                )\n",
    "                print(f\"Label : {f_mnist_test_images[idx][1]}, Output : {output}\")\n",
    "                ax = plt.figure().add_subplot()\n",
    "                ax.imshow(f_mnist_test_images[idx][0])\n",
    "                ax.set_xlabel(f\"{f_mnist_test_images[idx][1]}, {output}\")\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "            print(f\"Wrong : {wrong}, Correct : {correct}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Mean: {mean}, Std: {std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/wandb/run-20231118_233309-ric5aa45</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45' target=\"_blank\">2023-11-18_23-33-09</a></strong> to <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST' target=\"_blank\">https://wandb.ai/dicelab/CSE533_Fashion_MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45' target=\"_blank\">https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10000, 'batch_size': 2048, 'validation_intervals': 10, 'learning_rate': 0.001, 'early_stop_patience': 5, 'early_stop_delta': 1e-05, 'weight_decay': 1e-05, 'project': 'CSE533_Fashion_MNIST', 'use_wandb': True, 'current_time_str': '2023-11-18_23-33-09', 'checkpoints_path': 'checkpoints'}\n",
      "110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-06/anaconda3/envs/CSE533/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] T_loss: 5.45139, T_accuracy: 9.8282 | V_loss: 2.25833, V_accuracy: 9.7000 | Early stopping is stated! | T_time: 00:00:13, T_speed: 0.077\n",
      "[Epoch  10] T_loss: 0.65521, T_accuracy: 84.9173 | V_loss: 0.44328, V_accuracy: 86.1000 | V_loss decreased (2.25833 --> 0.44328). Saving model... | T_time: 00:01:54, T_speed: 0.088\n",
      "[Epoch  20] T_loss: 0.34840, T_accuracy: 92.2855 | V_loss: 0.34681, V_accuracy: 89.9600 | V_loss decreased (0.44328 --> 0.34681). Saving model... | T_time: 00:03:45, T_speed: 0.089\n",
      "[Epoch  30] T_loss: 0.17930, T_accuracy: 96.0782 | V_loss: 0.50589, V_accuracy: 89.3400 | Early stopping counter: 1 out of 5 | T_time: 00:05:37, T_speed: 0.089\n",
      "[Epoch  40] T_loss: 0.11321, T_accuracy: 97.5409 | V_loss: 0.54313, V_accuracy: 90.4400 | Early stopping counter: 2 out of 5 | T_time: 00:07:28, T_speed: 0.089\n",
      "[Epoch  50] T_loss: 0.06609, T_accuracy: 98.5255 | V_loss: 0.66283, V_accuracy: 90.1000 | Early stopping counter: 3 out of 5 | T_time: 00:09:20, T_speed: 0.089\n",
      "[Epoch  60] T_loss: 0.04268, T_accuracy: 99.0791 | V_loss: 0.71988, V_accuracy: 90.6400 | Early stopping counter: 4 out of 5 | T_time: 00:11:12, T_speed: 0.089\n",
      "[Epoch  70] T_loss: 0.03222, T_accuracy: 99.3245 | V_loss: 0.71243, V_accuracy: 90.0400 | Early stopping counter: 5 out of 5 *** TRAIN EARLY STOPPED! *** | T_time: 00:13:03, T_speed: 0.089\n",
      "Final training time: 00:13:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>Training accuracy (%)</td><td>▁▇▇█████</td></tr><tr><td>Training loss</td><td>█▂▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▁▇██████</td></tr><tr><td>Validation accuracy (%)</td><td>▁███████</td></tr><tr><td>Validation loss</td><td>█▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>70</td></tr><tr><td>Training accuracy (%)</td><td>99.32455</td></tr><tr><td>Training loss</td><td>0.03222</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.0894</td></tr><tr><td>Validation accuracy (%)</td><td>90.04</td></tr><tr><td>Validation loss</td><td>0.71243</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2023-11-18_23-33-09</strong> at: <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45' target=\"_blank\">https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231118_233309-ric5aa45/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL FILE: checkpoints/CSE533_Fashion_MNIST_checkpoint_latest.pt\n",
      "TEST RESULTS: 89.310%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Population must be a sequence.  For dicts or sets, use sorted(d).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     wandb\u001b[39m.\u001b[39mfinish()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m model_test(config, mean, std)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m#### Q1 Answer ####\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFashion Mnist Train Data\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms Mean\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, mean)\n",
      "\u001b[1;32m/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m correct_imgs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m wrong_imgs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m select \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49msample(f_mnist_test_images, \u001b[39m10\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m select:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     output \u001b[39m=\u001b[39m classification_tester\u001b[39m.\u001b[39mtest_single(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(img[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/CSE533/lib/python3.10/random.py:466\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    464\u001b[0m         population \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(population)\n\u001b[1;32m    465\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPopulation must be a sequence.  For dicts or sets, use sorted(d).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    467\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(population)\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m counts \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Population must be a sequence.  For dicts or sets, use sorted(d)."
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'epochs': 10_000,\n",
    "    'batch_size': 2048,\n",
    "    'validation_intervals': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'early_stop_patience': 5,\n",
    "    'early_stop_delta': 0.00001,\n",
    "    'weight_decay': 0.00001,\n",
    "    'project': \"CSE533_Fashion_MNIST\",\n",
    "    'use_wandb': True,\n",
    "    'current_time_str': datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S'),\n",
    "    'checkpoints_path': \"checkpoints\"\n",
    "}\n",
    "\n",
    "if not os.path.exists(config['checkpoints_path']):\n",
    "    os.makedirs(config['checkpoints_path'])\n",
    "\n",
    "wandb.init(\n",
    "    mode=\"online\" if config['use_wandb'] else \"disabled\",\n",
    "    project=config['project'],\n",
    "    notes=\"Homework3\",\n",
    "    tags=['googlenet', 'FashionMNIST'],\n",
    "    name=config['current_time_str'],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(wandb.config)\n",
    "\n",
    "mean = 0\n",
    "std = 0\n",
    "\n",
    "try:\n",
    "    mean, std = model_train(config)\n",
    "except:\n",
    "    wandb.finish()\n",
    "\n",
    "model_test(config, mean, std)\n",
    "\n",
    "print(\"#### Q1 Answer ####\")\n",
    "print(\"Fashion Mnist Train Data's Mean\\t:\", mean)\n",
    "print(\"Fashion Mnist Train Data's Std\\t:\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-06/anaconda3/envs/CSE533/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL FILE: checkpoints/CSE533_Fashion_MNIST_checkpoint_latest.pt\n",
      "TEST RESULTS: 89.310%\n",
      "Label : 2, Output : 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong : 1, Correct : 9\n",
      "Mean: 0.2862865924835205, Std: 0.35316306352615356\n"
     ]
    }
   ],
   "source": [
    "model_test(config, mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고찰\n",
    "### 과제 1번\n",
    "- 과제 1번은 Train Dataset이 매번 무작위로 정해지기 때문에 학습할 때 mean, std를 구하도록 해주었다.\n",
    "- 그래서 매번 실행할때마다 결과값이 바뀌게 된다.\n",
    "\n",
    "### 과제 2번\n",
    "- vadlidation accuracy: 93.4800\n",
    "- test accuracy: 90.3900\n",
    "- 위와 같은 결과가 나와 과제 1, 과제 2 모두 해결했다.\n",
    "- image augment를 사용해 학습 데이터를 추가해주었다.\n",
    "- weight decay = 0, learning rate = 0.001 인 상태로 먼저 모델을 학습시켰는데, 이때 결과가 좋았다.\n",
    "- 이때 Training loss가 0.02683이 나왔고, Validation loss가 0.6417이 나왔다.\n",
    "- Training accuracy는 99.417이었고, Validation accuracy는 90.62였다.\n",
    "- Training Dataset에 Overfitting되어 있다고 판단해 중간 checkpoint의 파라미터를 가져와 그 부분부터 학습시켰다.\n",
    "- 그때의 weight decay는 0.001, learning rate = 2e-5였다.\n",
    "- Training Dataset에 Overfitting되는 현상이 사라졌고, Validation accuracy도 증가하는 효과를 가져왔다.\n",
    "- 처음 weight decay를 0.001로 적용했을 때, learning rate가 1e-3이었다.\n",
    "- 학습을 시키니 첫 epoch 결과에서 계속 멤돌았다.\n",
    "- weight decay를 적용하지 않고, learning rate만 적용하면 잘 학습되었다.\n",
    "- 또한 weight decay를 0.001로 적용하고, learning rate를 2e-5로 설정해도 잘 학습되었다.\n",
    "- 항상 모든 hyperparameter들은 적당한 값을 설정해야 한다는 것을 알게 되었다.\n",
    "- 수업시간에 배운 내용을 직접 코딩해보고, 분석해보았다.\n",
    "- 이론만 아는것보다 실습을 통해 직접 구현을 해보니 도움이 많이 된다는 것을 느꼈다.\n",
    "\n",
    "### 과제 2번 추가\n",
    "- 계속 Hyperparameters를 바꿔가며 실험을 해보았다.\n",
    "- 많은 경우 Training Dataset에 Overfitting되어 validation accuracy는 낮아졌다.\n",
    "- learning rate 0.001, weight decay 0.00001를 주었을 때 좋은 결과가 나와 최종 제출을 이것으로 했다.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE533",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
