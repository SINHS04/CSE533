{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions from _01_code/_99_common_utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_linux():\n",
    "    if sys.platform.startswith(\"linux\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_windows():\n",
    "    if os.name == \"nt\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_mac():\n",
    "    if sys.platform == \"darwin\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_num_cpu_cores():\n",
    "    import multiprocessing\n",
    "    return multiprocessing.cpu_count()\n",
    "\n",
    "class DeltaTemplate(Template):\n",
    "    delimiter = \"%\"\n",
    "\n",
    "    def strfdelta(tdelta, fmt):\n",
    "        d = {\"D\": tdelta.days}\n",
    "        d[\"H\"], rem = divmod(tdelta.seconds, 3600)\n",
    "        d[\"M\"], d[\"S\"] = divmod(rem, 60)\n",
    "        t = DeltaTemplate(fmt)\n",
    "        return t.substitute(**d)\n",
    "\n",
    "def strfdelta(td, fmt):\n",
    "\n",
    "    # Get the timedelta’s sign and absolute number of seconds.\n",
    "    sign = \"-\" if td.days < 0 else \"+\"\n",
    "    secs = abs(td).total_seconds()\n",
    "\n",
    "    # Break the seconds into more readable quantities.\n",
    "    days, rem = divmod(secs, 86400)  # Seconds per day: 24 * 60 * 60\n",
    "    hours, rem = divmod(rem, 3600)  # Seconds per hour: 60 * 60\n",
    "    mins, secs = divmod(rem, 60)\n",
    "\n",
    "    # Format (as per above answers) and return the result string.\n",
    "    t = DeltaTemplate(fmt)\n",
    "    return t.substitute(\n",
    "        s=sign,\n",
    "        D=\"{:d}\".format(int(days)),\n",
    "        H=\"{:02d}\".format(int(hours)),\n",
    "        M=\"{:02d}\".format(int(mins)),\n",
    "        S=\"{:02d}\".format(int(secs)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [문제 1] Fashion MNIST 데이터 정규화를 위한 Mean과 Std값 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment function\n",
    "def augment_f_mnist_train(f_mnist_train):\n",
    "    f_mnist_train_transforms = nn.Sequential(\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.CenterCrop([28, 28]),\n",
    "        transforms.RandomCrop([28, 28]),\n",
    "    )\n",
    "\n",
    "    transformed_train_data = []\n",
    "\n",
    "    for image, label in f_mnist_train:\n",
    "        transformed_image = f_mnist_train_transforms(image)\n",
    "        transformed_train_data.append((transformed_image, label))\n",
    "\n",
    "    f_mnist_train = ConcatDataset([f_mnist_train, transformed_train_data])\n",
    "\n",
    "    return f_mnist_train\n",
    "\n",
    "def get_f_mnist_train_data():\n",
    "    data_path = \".\" \n",
    "\n",
    "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "\n",
    "    imgs = [img for img, _ in f_mnist_train]\n",
    "    imgs = torch.concat(imgs, dim=0)\n",
    "    mean = imgs.mean(dim=[0, 1, 2])\n",
    "    std = imgs.std(dim=[0, 1, 2])\n",
    "\n",
    "    ## augment ##\n",
    "    f_mnist_train = augment_f_mnist_train(f_mnist_train)\n",
    "    print(len(f_mnist_train))\n",
    "    ##############\n",
    "\n",
    "    num_data_loading_workers = get_num_cpu_cores() if is_linux() or is_windows() else 0\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    )\n",
    "    \n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms, mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_mnist_test_data(mean, std):\n",
    "    data_path = \".\"\n",
    "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet(CNN) Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_googlenet_model():\n",
    "    class Inception(nn.Module):\n",
    "        def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "            super(Inception, self).__init__(**kwargs)\n",
    "            self.b1_1 = nn.LazyConv2d(out_channels=c1, kernel_size=1)\n",
    "\n",
    "            self.b2_1 = nn.LazyConv2d(out_channels=c2[0], kernel_size=1)\n",
    "            self.b2_2 = nn.LazyConv2d(out_channels=c2[1], kernel_size=3, padding=1)\n",
    "\n",
    "            self.b3_1 = nn.LazyConv2d(out_channels=c3[0], kernel_size=1)\n",
    "            self.b3_2 = nn.LazyConv2d(out_channels=c3[1], kernel_size=5, padding=2)\n",
    "\n",
    "            self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "            self.b4_2 = nn.LazyConv2d(out_channels=c4, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            b1 = torch.relu(self.b1_1(x))\n",
    "            b2 = torch.relu(self.b2_2(torch.relu(self.b2_1(x))))\n",
    "            b3 = torch.relu(self.b3_2(torch.relu(self.b3_1(x))))\n",
    "            b4 = torch.relu(self.b4_2(self.b4_1(x)))\n",
    "            return torch.cat((b1, b2, b3, b4), dim=1)\n",
    "        \n",
    "    class InceptionAux(nn.Module):\n",
    "        def __init__(self, n_outputs, **kwargs):\n",
    "            super(InceptionAux, self).__init__(**kwargs)\n",
    "\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.LazyConv2d(out_channels=128, kernel_size=1),\n",
    "            )\n",
    "\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.LazyLinear(out_features=1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                nn.LazyLinear(out_features=n_outputs),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "        \n",
    "    class GoogleNet(nn.Module):\n",
    "        def __init__(self, n_outputs=10):\n",
    "            super(GoogleNet, self).__init__()\n",
    "            self.conv_block = nn.Sequential(self.conv_blk_1(), self.conv_blk_2())\n",
    "            self.inception_block_1 = self.inception_blk_1()\n",
    "            self.inception_block_2 = self.inception_blk_2()\n",
    "            self.inception_block_3 = self.inception_blk_3()\n",
    "            self.aux_1 = InceptionAux(n_outputs)\n",
    "            self.aux_2 = InceptionAux(n_outputs)\n",
    "\n",
    "        def conv_blk_1(self):\n",
    "            return nn.Sequential(\n",
    "                nn.LazyConv2d(out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            )\n",
    "        \n",
    "        def conv_blk_2(self):\n",
    "            return nn.Sequential(\n",
    "                nn.LazyConv2d(out_channels=64, kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.LazyConv2d(out_channels=192, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            )\n",
    "        \n",
    "        def inception_blk_1(self):\n",
    "            return nn.Sequential(\n",
    "                Inception(c1=64, c2=(96, 128), c3=(16, 32), c4=32),\n",
    "                Inception(c1=128, c2=(128, 192), c3=(32, 96), c4=64),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                Inception(c1=192, c2=(96, 208), c3=(16, 48), c4=64),\n",
    "            )\n",
    "        \n",
    "        def inception_blk_2(self):\n",
    "            return nn.Sequential(\n",
    "                Inception(c1=160, c2=(112, 224), c3=(24, 64), c4=64),\n",
    "                Inception(c1=128, c2=(128, 256), c3=(24, 64), c4=64),\n",
    "                Inception(c1=112, c2=(144, 288), c3=(32, 64), c4=64),\n",
    "            )\n",
    "        \n",
    "        def inception_blk_3(self):\n",
    "            return nn.Sequential(\n",
    "                Inception(c1=256, c2=(160, 320), c3=(32, 128), c4=128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                Inception(c1=256, c2=(160, 320), c3=(32, 128), c4=128),\n",
    "                Inception(c1=384, c2=(192, 384), c3=(48, 128), c4=128),\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv_block(x)\n",
    "            x = self.inception_block_1(x)\n",
    "            aux_out_1 = self.aux_1(x)\n",
    "            x = self.inception_block_2(x)\n",
    "            aux_out_2 = self.aux_2(x)\n",
    "            x = self.inception_block_3(x)\n",
    "            return x, aux_out_1, aux_out_2\n",
    "\n",
    "    my_model = GoogleNet()\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "  \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "  def __init__(self, patience=10, delta=0.00001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
    "    self.patience = patience\n",
    "    self.counter = 0\n",
    "    self.delta = delta\n",
    "\n",
    "    self.val_loss_min = None\n",
    "    self.file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
    "    )\n",
    "    self.latest_file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "    )\n",
    "\n",
    "  def check_and_save(self, new_validation_loss, model):\n",
    "    early_stop = False\n",
    "\n",
    "    if self.val_loss_min is None:\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      message = f'Early stopping is stated!'\n",
    "    elif new_validation_loss < self.val_loss_min - self.delta:\n",
    "      message = f'V_loss decreased ({self.val_loss_min:7.5f} --> {new_validation_loss:7.5f}). Saving model...'\n",
    "      self.save_checkpoint(new_validation_loss, model)\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      self.counter = 0\n",
    "    else:\n",
    "      self.counter += 1\n",
    "      message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
    "      if self.counter >= self.patience:\n",
    "        early_stop = True\n",
    "        message += \" *** TRAIN EARLY STOPPED! ***\"\n",
    "\n",
    "    return message, early_stop\n",
    "\n",
    "  def save_checkpoint(self, val_loss, model):\n",
    "    '''Saves model when validation loss decrease.'''\n",
    "    torch.save(model.state_dict(), self.file_path)\n",
    "    torch.save(model.state_dict(), self.latest_file_path)\n",
    "    self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClassificationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTrainer:\n",
    "  def __init__(\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "  ):\n",
    "    self.project_name = project_name\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.train_data_loader = train_data_loader\n",
    "    self.validation_data_loader = validation_data_loader\n",
    "    self.transforms = transforms\n",
    "    self.run_time_str = run_time_str\n",
    "    self.wandb = wandb\n",
    "    self.device = device\n",
    "    self.checkpoint_file_path = checkpoint_file_path\n",
    "\n",
    "    # Use a built-in loss function\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  def do_train(self):\n",
    "    self.model.train()  # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_train = 0.0\n",
    "    num_corrects_train = 0\n",
    "    num_trained_samples = 0\n",
    "    num_trains = 0\n",
    "\n",
    "    for train_batch in self.train_data_loader:\n",
    "      input_train, target_train = train_batch\n",
    "      input_train = input_train.to(device=self.device)\n",
    "      target_train = target_train.to(device=self.device)\n",
    "\n",
    "      if self.transforms:\n",
    "        input_train = self.transforms(input_train)\n",
    "\n",
    "      output_train = self.model(input_train)\n",
    "\n",
    "      loss = self.loss_fn(output_train, target_train)\n",
    "      loss_train += loss.item()\n",
    "\n",
    "      predicted_train = torch.argmax(output_train, dim=1)\n",
    "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "      num_trained_samples += len(input_train)\n",
    "      num_trains += 1\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "    train_loss = loss_train / num_trains\n",
    "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "  def do_validation(self):\n",
    "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_corrects_validation = 0\n",
    "    num_validated_samples = 0\n",
    "    num_validations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in self.validation_data_loader:\n",
    "        input_validation, target_validation = validation_batch\n",
    "        input_validation = input_validation.to(device=self.device)\n",
    "        target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "        if self.transforms:\n",
    "          input_validation = self.transforms(input_validation)\n",
    "\n",
    "        output_validation = self.model(input_validation)\n",
    "        loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
    "\n",
    "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "        num_validated_samples += len(input_validation)\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "    return validation_loss, validation_accuracy\n",
    "\n",
    "  def train_loop(self):\n",
    "    early_stopping = EarlyStopping(\n",
    "      patience=self.wandb.config.early_stop_patience,\n",
    "      delta=self.wandb.config.early_stop_delta,\n",
    "      project_name=self.project_name,\n",
    "      checkpoint_file_path=self.checkpoint_file_path,\n",
    "      run_time_str=self.run_time_str\n",
    "    )\n",
    "    n_epochs = self.wandb.config.epochs\n",
    "    training_start_time = datetime.now()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      train_loss, train_accuracy = self.do_train()\n",
    "\n",
    "      if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "        validation_loss, validation_accuracy = self.do_validation()\n",
    "\n",
    "        elapsed_time = datetime.now() - training_start_time\n",
    "        epoch_per_second = 0 if elapsed_time.seconds == 0 else epoch / elapsed_time.seconds\n",
    "\n",
    "        message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "\n",
    "        print(\n",
    "          f\"[Epoch {epoch:>3}] \"\n",
    "          f\"T_loss: {train_loss:7.5f}, \"\n",
    "          f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "          f\"V_loss: {validation_loss:7.5f}, \"\n",
    "          f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "          f\"{message} | \"\n",
    "          f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "          f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "        )\n",
    "\n",
    "        self.wandb.log({\n",
    "          \"Epoch\": epoch,\n",
    "          \"Training loss\": train_loss,\n",
    "          \"Training accuracy (%)\": train_accuracy,\n",
    "          \"Validation loss\": validation_loss,\n",
    "          \"Validation accuracy (%)\": validation_accuracy,\n",
    "          \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "        })\n",
    "\n",
    "        if early_stop:\n",
    "          break\n",
    "\n",
    "    elapsed_time = datetime.now() - training_start_time\n",
    "    print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClassificationTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTester:\n",
    "  def __init__(self, project_name, model, test_data_loader, transforms, checkpoint_file_path):\n",
    "    self.project_name = project_name\n",
    "    self.model = model\n",
    "    self.test_data_loader = test_data_loader\n",
    "    self.transforms = transforms\n",
    "\n",
    "    self.latest_file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "    )\n",
    "\n",
    "    print(\"MODEL FILE: {0}\".format(self.latest_file_path))\n",
    "\n",
    "    self.model.load_state_dict(torch.load(self.latest_file_path, map_location=torch.device('cpu')))\n",
    "\n",
    "  def test(self):\n",
    "    self.model.eval()    # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    num_corrects_test = 0\n",
    "    num_tested_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for test_batch in self.test_data_loader:\n",
    "        input_test, target_test = test_batch\n",
    "\n",
    "        input_test = self.transforms(input_test)\n",
    "\n",
    "        output_test, _, _ = self.model(input_test)\n",
    "\n",
    "        predicted_test = torch.argmax(output_test, dim=1)\n",
    "        num_corrects_test += torch.sum(torch.eq(predicted_test, target_test))\n",
    "\n",
    "        num_tested_samples += len(input_test)\n",
    "\n",
    "      test_accuracy = 100.0 * num_corrects_test / num_tested_samples\n",
    "\n",
    "    print(f\"TEST RESULTS: {test_accuracy:6.3f}%\")\n",
    "\n",
    "  def test_single(self, input_test):\n",
    "    self.model.eval()    # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    with torch.no_grad():\n",
    "      input_test = self.transforms(input_test)\n",
    "\n",
    "      output_test, _, _ = self.model(input_test)\n",
    "      predicted_test = torch.argmax(output_test, dim=1)\n",
    "\n",
    "    return predicted_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNetClassificationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNetClassificationTrainer(ClassificationTrainer):\n",
    "  def __init__(\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "  ):\n",
    "    super(GoogLeNetClassificationTrainer, self).__init__(\n",
    "      project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "      run_time_str, wandb, device, checkpoint_file_path\n",
    "    )\n",
    "\n",
    "  def do_train(self):\n",
    "    self.model.train()  # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_train = 0.0\n",
    "    num_corrects_train = 0\n",
    "    num_trained_samples = 0\n",
    "    num_trains = 0\n",
    "\n",
    "    for train_batch in self.train_data_loader:\n",
    "      input_train, target_train = train_batch\n",
    "      input_train = input_train.to(device=self.device)\n",
    "      target_train = target_train.to(device=self.device)\n",
    "\n",
    "      input_train = self.transforms(input_train)\n",
    "\n",
    "      output_train, output_train_ax_1, output_train_ax_2 = self.model(input_train)\n",
    "      loss = self.loss_fn(output_train, target_train)\n",
    "      loss_aux_1 = self.loss_fn(output_train_ax_1, target_train)\n",
    "      loss_aux_2 = self.loss_fn(output_train_ax_2, target_train)\n",
    "      loss += 0.3 * (loss_aux_1 + loss_aux_2)\n",
    "\n",
    "      loss_train += loss.item()\n",
    "\n",
    "      predicted_train = torch.argmax(output_train, dim=1)\n",
    "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "      num_trained_samples += len(input_train)\n",
    "      num_trains += 1\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "    train_loss = loss_train / num_trains\n",
    "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "  def do_validation(self):\n",
    "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_corrects_validation = 0\n",
    "    num_validated_samples = 0\n",
    "    num_validations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in self.validation_data_loader:\n",
    "        input_validation, target_validation = validation_batch\n",
    "        input_validation = input_validation.to(device=self.device)\n",
    "        target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "        input_validation = self.transforms(input_validation)\n",
    "\n",
    "        output_validation, output_validation_ax_1, output_validation_ax_2 = self.model(input_validation)\n",
    "        loss_validation = self.loss_fn(output_validation, target_validation)\n",
    "        loss_validation_aux_1 = self.loss_fn(output_validation_ax_1, target_validation)\n",
    "        loss_validation_aux_2 = self.loss_fn(output_validation_ax_2, target_validation)\n",
    "        loss_validation += 0.3 * (loss_validation_aux_1 + loss_validation_aux_2)\n",
    "        loss_validation += loss_validation.item()\n",
    "\n",
    "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "        num_validated_samples += len(input_validation)\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(config):\n",
    "    train_data_loader, validation_data_loader, f_mnist_transforms, mean, std = get_f_mnist_train_data()\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = get_googlenet_model()\n",
    "    # best_path = 'checkpoints/CSE533_Fashion_MNIST_checkpoint_2023-11-18_00-17-29.pt'\n",
    "    # best_path = 'checkpoints/CSE533_Fashion_MNIST_checkpoint_2023-11-18_05-14-41.pt'\n",
    "    # model.load_state_dict(torch.load(best_path, map_location=torch.device('cpu')))\n",
    "    model.to(device)\n",
    "\n",
    "    summary(\n",
    "        model = model,\n",
    "        input_size=(1, 1, 28, 28),\n",
    "        col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\", \"mult_adds\"]\n",
    "    )\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=wandb.config.learning_rate,\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "\n",
    "    classification_trainer = GoogLeNetClassificationTrainer(\n",
    "        config['project'], model, optimizer, train_data_loader, validation_data_loader, f_mnist_transforms,\n",
    "        config['current_time_str'], wandb, device, config['checkpoints_path']\n",
    "    )\n",
    "\n",
    "    classification_trainer.train_loop()\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(config, mean, std):\n",
    "    f_mnist_test_images, test_data_loader, f_mnist_transforms = get_f_mnist_test_data(mean, std)\n",
    "\n",
    "    test_model = get_googlenet_model()\n",
    "\n",
    "    classification_tester = ClassificationTester(\n",
    "        config['project'], test_model, test_data_loader, f_mnist_transforms, config['checkpoints_path']\n",
    "    )\n",
    "    classification_tester.test()\n",
    "\n",
    "    # img, label = f_mnist_test_images[0]\n",
    "    # print(\"     LABEL:\", label)\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "    \n",
    "    # output = classification_tester.test_single(\n",
    "    #     torch.tensor(np.array(f_mnist_test_images[0][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "    # )\n",
    "    # print(\"PREDICTION:\", output)\n",
    "\n",
    "    while True:\n",
    "        correct = 0\n",
    "        wrong = 0\n",
    "        correct_imgs = []\n",
    "        wrong_imgs = []\n",
    "\n",
    "        number = list([i for i in range(10_000)])\n",
    "        select = random.sample(number, 10)\n",
    "        for idx in select:\n",
    "            output = classification_tester.test_single(\n",
    "                torch.tensor(np.array(f_mnist_test_images[idx][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "            )\n",
    "            label = f_mnist_test_images[idx][1]\n",
    "            if label == output:\n",
    "                correct += 1\n",
    "                correct_imgs.append(f_mnist_test_images[idx])\n",
    "            else:\n",
    "                wrong += 1\n",
    "                wrong_imgs.append(f_mnist_test_images[idx])\n",
    "\n",
    "        if wrong > 0:\n",
    "            for img in wrong_imgs:\n",
    "                output = classification_tester.test_single(\n",
    "                    torch.tensor(np.array(f_mnist_test_images[idx][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "                )\n",
    "                print(f\"Label : {f_mnist_test_images[idx][1]}, Output : {output}\")\n",
    "                ax = plt.figure().add_subplot()\n",
    "                ax.imshow(f_mnist_test_images[idx][0])\n",
    "                ax.set_xlabel(f\"{f_mnist_test_images[idx][1]}, {output}\")\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "            print(f\"Wrong : {wrong}, Correct : {correct}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/wandb/run-20231118_233309-ric5aa45</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45' target=\"_blank\">2023-11-18_23-33-09</a></strong> to <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST' target=\"_blank\">https://wandb.ai/dicelab/CSE533_Fashion_MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45' target=\"_blank\">https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10000, 'batch_size': 2048, 'validation_intervals': 10, 'learning_rate': 0.001, 'early_stop_patience': 5, 'early_stop_delta': 1e-05, 'weight_decay': 1e-05, 'project': 'CSE533_Fashion_MNIST', 'use_wandb': True, 'current_time_str': '2023-11-18_23-33-09', 'checkpoints_path': 'checkpoints'}\n",
      "110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-06/anaconda3/envs/CSE533/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] T_loss: 5.45139, T_accuracy: 9.8282 | V_loss: 2.25833, V_accuracy: 9.7000 | Early stopping is stated! | T_time: 00:00:13, T_speed: 0.077\n",
      "[Epoch  10] T_loss: 0.65521, T_accuracy: 84.9173 | V_loss: 0.44328, V_accuracy: 86.1000 | V_loss decreased (2.25833 --> 0.44328). Saving model... | T_time: 00:01:54, T_speed: 0.088\n",
      "[Epoch  20] T_loss: 0.34840, T_accuracy: 92.2855 | V_loss: 0.34681, V_accuracy: 89.9600 | V_loss decreased (0.44328 --> 0.34681). Saving model... | T_time: 00:03:45, T_speed: 0.089\n",
      "[Epoch  30] T_loss: 0.17930, T_accuracy: 96.0782 | V_loss: 0.50589, V_accuracy: 89.3400 | Early stopping counter: 1 out of 5 | T_time: 00:05:37, T_speed: 0.089\n",
      "[Epoch  40] T_loss: 0.11321, T_accuracy: 97.5409 | V_loss: 0.54313, V_accuracy: 90.4400 | Early stopping counter: 2 out of 5 | T_time: 00:07:28, T_speed: 0.089\n",
      "[Epoch  50] T_loss: 0.06609, T_accuracy: 98.5255 | V_loss: 0.66283, V_accuracy: 90.1000 | Early stopping counter: 3 out of 5 | T_time: 00:09:20, T_speed: 0.089\n",
      "[Epoch  60] T_loss: 0.04268, T_accuracy: 99.0791 | V_loss: 0.71988, V_accuracy: 90.6400 | Early stopping counter: 4 out of 5 | T_time: 00:11:12, T_speed: 0.089\n",
      "[Epoch  70] T_loss: 0.03222, T_accuracy: 99.3245 | V_loss: 0.71243, V_accuracy: 90.0400 | Early stopping counter: 5 out of 5 *** TRAIN EARLY STOPPED! *** | T_time: 00:13:03, T_speed: 0.089\n",
      "Final training time: 00:13:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>Training accuracy (%)</td><td>▁▇▇█████</td></tr><tr><td>Training loss</td><td>█▂▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▁▇██████</td></tr><tr><td>Validation accuracy (%)</td><td>▁███████</td></tr><tr><td>Validation loss</td><td>█▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>70</td></tr><tr><td>Training accuracy (%)</td><td>99.32455</td></tr><tr><td>Training loss</td><td>0.03222</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.0894</td></tr><tr><td>Validation accuracy (%)</td><td>90.04</td></tr><tr><td>Validation loss</td><td>0.71243</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2023-11-18_23-33-09</strong> at: <a href='https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45' target=\"_blank\">https://wandb.ai/dicelab/CSE533_Fashion_MNIST/runs/ric5aa45</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231118_233309-ric5aa45/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL FILE: checkpoints/CSE533_Fashion_MNIST_checkpoint_latest.pt\n",
      "TEST RESULTS: 89.310%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Population must be a sequence.  For dicts or sets, use sorted(d).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     wandb\u001b[39m.\u001b[39mfinish()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m model_test(config, mean, std)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m#### Q1 Answer ####\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFashion Mnist Train Data\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms Mean\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, mean)\n",
      "\u001b[1;32m/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m correct_imgs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m wrong_imgs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m select \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49msample(f_mnist_test_images, \u001b[39m10\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m select:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     output \u001b[39m=\u001b[39m classification_tester\u001b[39m.\u001b[39mtest_single(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(img[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B54/home/nlp-06/CSE533/assignment/CSE533/Assignment/hw3/homework3.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/CSE533/lib/python3.10/random.py:466\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    464\u001b[0m         population \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(population)\n\u001b[1;32m    465\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPopulation must be a sequence.  For dicts or sets, use sorted(d).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    467\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(population)\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m counts \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Population must be a sequence.  For dicts or sets, use sorted(d)."
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'epochs': 10_000,\n",
    "    'batch_size': 2048,\n",
    "    'validation_intervals': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'early_stop_patience': 5,\n",
    "    'early_stop_delta': 0.00001,\n",
    "    'weight_decay': 0.00001,\n",
    "    'project': \"CSE533_Fashion_MNIST\",\n",
    "    'use_wandb': True,\n",
    "    'current_time_str': datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S'),\n",
    "    'checkpoints_path': \"checkpoints\"\n",
    "}\n",
    "\n",
    "if not os.path.exists(config['checkpoints_path']):\n",
    "    os.makedirs(config['checkpoints_path'])\n",
    "\n",
    "wandb.init(\n",
    "    mode=\"online\" if config['use_wandb'] else \"disabled\",\n",
    "    project=config['project'],\n",
    "    notes=\"Homework3\",\n",
    "    tags=['googlenet', 'FashionMNIST'],\n",
    "    name=config['current_time_str'],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(wandb.config)\n",
    "\n",
    "mean = 0\n",
    "std = 0\n",
    "\n",
    "try:\n",
    "    mean, std = model_train(config)\n",
    "except:\n",
    "    wandb.finish()\n",
    "\n",
    "model_test(config, mean, std)\n",
    "\n",
    "print(\"#### Q1 Answer ####\")\n",
    "print(\"Fashion Mnist Train Data's Mean\\t:\", mean)\n",
    "print(\"Fashion Mnist Train Data's Std\\t:\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-06/anaconda3/envs/CSE533/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL FILE: checkpoints/CSE533_Fashion_MNIST_checkpoint_latest.pt\n",
      "TEST RESULTS: 89.310%\n",
      "Label : 3, Output : 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong : 1, Correct : 9\n"
     ]
    }
   ],
   "source": [
    "model_test(config, mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고찰\n",
    "### 과제 1번\n",
    "- 과제 1번은 Train Dataset이 매번 무작위로 정해지기 때문에 학습할 때 mean, std를 구하도록 해주었다.\n",
    "- 그래서 매번 실행할때마다 결과값이 바뀌게 된다.\n",
    "\n",
    "### 과제 2번\n",
    "- vadlidation accuracy: 93.4800\n",
    "- test accuracy: 90.3900\n",
    "- 위와 같은 결과가 나와 과제 1, 과제 2 모두 해결했다.\n",
    "- image augment를 사용해 학습 데이터를 추가해주었다.\n",
    "- weight decay = 0, learning rate = 0.001 인 상태로 먼저 모델을 학습시켰는데, 이때 결과가 좋았다.\n",
    "- 이때 Training loss가 0.02683이 나왔고, Validation loss가 0.6417이 나왔다.\n",
    "- Training accuracy는 99.417이었고, Validation accuracy는 90.62였다.\n",
    "- Training Dataset에 Overfitting되어 있다고 판단해 중간 checkpoint의 파라미터를 가져와 그 부분부터 학습시켰다.\n",
    "- 그때의 weight decay는 0.001, learning rate = 2e-5였다.\n",
    "- Training Dataset에 Overfitting되는 현상이 사라졌고, Validation accuracy도 증가하는 효과를 가져왔다.\n",
    "- 처음 weight decay를 0.001로 적용했을 때, learning rate가 1e-3이었다.\n",
    "- 학습을 시키니 첫 epoch 결과에서 계속 멤돌았다.\n",
    "- weight decay를 적용하지 않고, learning rate만 적용하면 잘 학습되었다.\n",
    "- 또한 weight decay를 0.001로 적용하고, learning rate를 2e-5로 설정해도 잘 학습되었다.\n",
    "- 항상 모든 hyperparameter들은 적당한 값을 설정해야 한다는 것을 알게 되었다.\n",
    "- 수업시간에 배운 내용을 직접 코딩해보고, 분석해보았다.\n",
    "- 이론만 아는것보다 실습을 통해 직접 구현을 해보니 도움이 많이 된다는 것을 느꼈다.\n",
    "\n",
    "### 과제 2번 추가\n",
    "- 계속 Hyperparameters를 바꿔가며 실험을 해보았다.\n",
    "- 많은 경우 Training Dataset에 Overfitting되어 validation accuracy는 낮아졌다.\n",
    "- learning rate 0.001, weight decay 0.00001를 주었을 때 좋은 결과가 나와 최종 제출을 이것으로 했다.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE533",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
